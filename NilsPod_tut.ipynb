{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NilsPod Tutorial \n",
    "============\n",
    "## Ferienakademie 2019 \n",
    "### Luca & Janis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib ipympl\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NilsPod Python Lib\n",
    "=======\n",
    "Modules:\n",
    "- session_base\n",
    "- calibration_utils\n",
    "- consts\n",
    "- dataset\n",
    "- datastream\n",
    "- exceptions\n",
    "- header\n",
    "- legacy\n",
    "- session\n",
    "- utils\n",
    "<br>The session and dataset module are most likely the most important ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Sessions\n",
    "=========\n",
    "\n",
    "A Session groups multiple Datasets from sensors. The Session module itself does not make any assumptions about how and when the datasets were recorded. It just poses an interface to manipulate the given datasets simultaneously, for instance, we can extract a certain period of interest from all sessions or calibrate certain sensors of the NilsPods. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This session has 2 datasets\n"
     ]
    }
   ],
   "source": [
    "from NilsPodLib import Dataset, Session, SyncedSession, calibration_utils\n",
    "\n",
    "FILEPATH = Path('./Data/')\n",
    "#In many cases we want to include all log-files in a certain dir:\n",
    "datasets = [Dataset.from_bin_file(d) for d in FILEPATH.glob('*.bin')]\n",
    "session = Session(datasets)\n",
    "#session = Session.from_folder_path(FILEPATH, filter_pattern='*.bin')\n",
    "print('This session has {} datasets'.format(len(session.datasets)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gyro of 9433 has the length 24100\n",
      "acc of 9433 has the length 24100\n",
      "gyro of e0ef has the length 24096\n",
      "acc of e0ef has the length 24096\n",
      "ecg of e0ef has the length 24096\n"
     ]
    }
   ],
   "source": [
    "for ds in session.datasets:\n",
    "    for name, d in ds.datastreams:\n",
    "        print(f'{name} of {ds.info.sensor_id} has the length {len(d.data)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Session Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Downsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gyro of 9433 has the length 12050\n",
      "acc of 9433 has the length 12050\n",
      "gyro of e0ef has the length 12048\n",
      "acc of e0ef has the length 12048\n",
      "ecg of e0ef has the length 12048\n"
     ]
    }
   ],
   "source": [
    "downsampled_session = session.downsample(factor=2)\n",
    "for ds in downsampled_session.datasets:\n",
    "    for name, d in ds.datastreams:\n",
    "        print(f'{name} of {ds.info.sensor_id} has the length {len(d.data)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calibration\n",
    "Sadly, we used two sensors that do not have any calibrations..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9433\n"
     ]
    }
   ],
   "source": [
    "ds = session.datasets[0]\n",
    "print(ds.info.sensor_id)\n",
    "#your_cal = calibration_utils.find_calibrations_for_sensor(ds.info.sensor_id, folder='/Data') # Alternative: Select a callibration from a list of given calibrations\n",
    "#calibrated_acc = session.calibrate_gyro(your_cal[0])\n",
    "#calibrated_acc.data_as_df()[1].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b67a888dd7a04066a4455431a1191892",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "777cf0dc47e24f1eb1a2498060c59681",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "calibrated_acc = session.factory_calibrate_gyro() # Set facotry calibtration settings\n",
    "ax = calibrated_acc.data_as_df()[0].plot()\n",
    "ax2 = calibrated_acc.data_as_df()[1].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b0cf51cd0374b6c9aecb719e2620ef8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "932799dde384439ebce54eb0acaa1a08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x175a8d40470>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted = session.cut(7000, 10000,step=1) \n",
    "extracted.data_as_df()[0].plot()\n",
    "extracted.data_as_df()[1].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### General Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The included sensors are: ('9433', 'e0ef')\n",
      "The samplingrates are: (256.0, 256.0)\n",
      "The enabled sensor are: (('gyro', 'acc'), ('gyro', 'acc', 'ecg')) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Further you can use the Proxy Attribute `info` to access the header infos of all sensors at the same time\n",
    "print(f'The included sensors are: {session.info.sensor_id}')\n",
    "print(f'The samplingrates are: {session.info.sampling_rate_hz}')\n",
    "print(f'The enabled sensor are: {session.info.enabled_sensors} \\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Synchronised Session\n",
    "====================\n",
    "The library differentiates between synchronised and not synchronised session. Synchronized means that all datasets have the same length and the exact same counter.<br>\n",
    "If your session was recorded synchronously you should use a SyncedSession. However, datasets from different measurements can be forced into a synchronized session (VALIDATE_ON_INIT=False).<br>\n",
    "A SyncedSession always consits of one master and at least one slave. Hereby, the master conduces as a clock."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The master of the session is e0ef\n",
      "The slaves of the session are ['9433']\n",
      "9433 has the same counter than master (e0ef)\n"
     ]
    }
   ],
   "source": [
    "session = SyncedSession.from_folder_path(FILEPATH)\n",
    "\n",
    "# This will also validate that all datasets are compatible to be syncronised.\n",
    "# If you need to switch off this validation, you can disable it using:\n",
    "SyncedSession.VALIDATE_ON_INIT = False\n",
    "session = SyncedSession.from_folder_path(FILEPATH)\n",
    "\n",
    "# For synced sessions you can get the datasets of the master and the slaves separately\n",
    "\n",
    "print('The master of the session is', session.master.info.sensor_id)\n",
    "print('The slaves of the session are', [d.info.sensor_id for d in session.slaves])\n",
    "\n",
    "# To make use of the sync information, all datasets need to be aligned. This can be done using the `cut_to_syncregion`\n",
    "# method.\n",
    "\n",
    "cut_session = session.cut_to_syncregion()\n",
    "\n",
    "# After this all session are aligned and the dataset counter are identical\n",
    "\n",
    "for d in cut_session.slaves:\n",
    "    if np.array_equal(d.counter, cut_session.master.counter) is True:\n",
    "        print('{} has the same counter than master ({})'.format(d.info.sensor_id, cut_session.master.info.sensor_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>Now, all dataset have the same length and same index.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gyro of 9433 has the length 22649\n",
      "acc of 9433 has the length 22649\n",
      "gyro of e0ef has the length 22649\n",
      "acc of e0ef has the length 22649\n",
      "ecg of e0ef has the length 22649\n"
     ]
    }
   ],
   "source": [
    "for ds in cut_session.datasets:\n",
    "    for name, d in ds.datastreams:\n",
    "        print(f'{name} of {ds.info.sensor_id} has the length {len(d.data)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>We can use all functions of normal Sessions with SyncedSessions as well. Additionally, several validations can be checked.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All provided sessions have overlapping recording times: True\n",
      "All sensors had the same sampling rate: True\n",
      "There is only 1 master and all other sensors were configured as slaves: (True, True)\n"
     ]
    }
   ],
   "source": [
    "print(f'All provided sessions have overlapping recording times: {cut_session._validate_overlapping_record_time()}')\n",
    "print(f'All sensors had the same sampling rate: {cut_session._validate_sampling_rate()}')\n",
    "print(f'There is only 1 master and all other sensors were configured as slaves: {cut_session._validate_sync_role()}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
